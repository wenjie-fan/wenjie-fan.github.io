---
title: "Miscellaneous"
layout: about
hidemeta: true
description: ""
weight:
slug: ""
draft: false # 是否为草稿
comments: true
reward: false
showToc: true # 显示目录
TocOpen: true # 自动展开目录
disableShare: true # 底部不显示分享栏
showbreadcrumbs: false
cover:
    image: ""
    caption: ""
    alt: ""
    relative: false
---

---
### Latent Dirichlet Allocation via Gibbs sampling
Latent Dirichlet Allocation (LDA) is a classic model for topic modelling, which often appears in natural language processing. The model can also be extended to analyse, for example, transcriptomics data. Below is an implementation via a Gibbs sampler, tested on a corpus of short articles. This Markov chain Monte Carlo (MCMC) approach was proposed by Thomas L. Griffiths and Mark Steyvers in their paper "Finding scientific topics". </p>
[<span style="display:inline-block;background-color:rgb(180,180,180);color:white;padding:0px 10px;border-radius:4px;"><font size='3'>HTML</font></span>](LDA_CG.html)

---